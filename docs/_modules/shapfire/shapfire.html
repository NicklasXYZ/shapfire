

<!doctype html>
<html lang="en" class="no-js">
  <head>

      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">



      <link rel="icon" href="../../_static/favicon.ico">



        <title>shapfire.shapfire - ShapFire</title>



      <link rel="stylesheet" href="../../_static/stylesheets/main.8674dc46.min.css">


        <link rel="stylesheet" href="../../_static/stylesheets/palette.92c9fe4a.min.css">








        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>


        <link rel="stylesheet" type="text/css" href="../../_static/extra_cssv2.css" />
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>





  </head>









    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan">



      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>

    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">

    </div>
    <div data-md-component="announce">

    </div>

      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">

        </aside>
      </div>




<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="ShapFire" class="md-header__button md-logo" aria-label="ShapFire" data-md-component="logo">
      <img src="../../_static/fire.svg" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ShapFire
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">

              shapfire.shapfire

          </span>
        </div>
      </div>
    </div>

      <form class="md-header__option" data-md-component="palette">



          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">


      </form>



      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">

          <a href="javascript:void(0)" class="md-search__icon md-icon" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>

        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>

    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>


      <div class="md-header__source">
        <a href="https://github.com/nicklasxyz/shapfire/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ShapFire
  </div>
</a>
      </div>

  </nav>

</header>

    <div class="md-container" data-md-component="container">








      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">



              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">





<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="ShapFire" class="md-nav__button md-logo" aria-label="ShapFire" data-md-component="logo">
      <img src="../../_static/fire.svg" alt="logo">
    </a>
    ShapFire
  </label>

    <div class="md-nav__source">
      <a href="https://github.com/nicklasxyz/shapfire/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    ShapFire
  </div>
</a>
    </div>

  <ul class="md-nav__list" data-md-scrollfix>








    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        <span title="index (document)" class="md-ellipsis">About</span>
      </a>
    </li>










    <li class="md-nav__item">
      <a href="../../source/examples/index.html" class="md-nav__link">
        <span title="source/examples/index (document)" class="md-ellipsis">Examples</span>
      </a>
    </li>










    <li class="md-nav__item">
      <a href="../../source/api/api_reference.html" class="md-nav__link">
        <span title="source/api/api_reference (document)" class="md-ellipsis">API Reference</span>
      </a>
    </li>



  </ul>
</nav>
                  </div>
                </div>
              </div>



          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset" role="main">

  <a href="https://github.com/nicklasxyz/shapfire/blob/main/docs/_modules/shapfire/shapfire.rst" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



  <h1>Source code for shapfire.shapfire</h1><div class="highlight"><pre>
<span></span><code><span class="sd">&quot;&quot;&quot;This module contains the main implementation of the ShapFire method for</span>
<span class="sd">feature ranking and selection.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">typing</span>

<span class="kn">import</span> <span class="nn">lightgbm</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">matplotlib.axes</span> <span class="kn">import</span> <span class="n">Axes</span>
<span class="kn">from</span> <span class="nn">matplotlib.figure</span> <span class="kn">import</span> <span class="n">Figure</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseEstimator</span><span class="p">,</span>
    <span class="n">TransformerMixin</span><span class="p">,</span>
    <span class="n">is_classifier</span><span class="p">,</span>
    <span class="n">is_regressor</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GridSearchCV</span><span class="p">,</span>
    <span class="n">RandomizedSearchCV</span><span class="p">,</span>
    <span class="n">RepeatedKFold</span><span class="p">,</span>
    <span class="n">RepeatedStratifiedKFold</span><span class="p">,</span>
    <span class="n">cross_val_score</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">shapfire.utils</span> <span class="k">as</span> <span class="nn">utils</span>
<span class="kn">from</span> <span class="nn">shapfire.clustering</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoHierarchicalAssociationClustering</span><span class="p">,</span>
    <span class="n">ClusterSampler</span><span class="p">,</span>
    <span class="n">_identify_colinear_features</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">shapfire.plotting</span> <span class="kn">import</span> <span class="n">ShapFirePlottingInterface</span>

<span class="n">DEFAULT_SPLITS</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
<span class="sd">&quot;&quot;&quot;The default number of folds a dataset should be divided into in a</span>
<span class="sd">cross-validation.&quot;&quot;&quot;</span>

<span class="n">DEFAULT_REPEATS</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="sd">&quot;&quot;&quot;The number of times, in a cross-validation, the division of a dataset into a</span>
<span class="sd">certain number of folds should be repeated.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Valid hyperparameter search methods</span>
<span class="n">HYPERPARAMETER_SEARCH_METHODS</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">RandomizedSearchCV</span><span class="p">,</span>
    <span class="n">GridSearchCV</span><span class="p">,</span>
    <span class="kc">None</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Valid estimator classes</span>
<span class="n">ESTIMATOR_CLASSES</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
    <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
    <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
    <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># NOTE: All scorer objects follow the convention that higher return values are</span>
<span class="c1"># better than lower return values.</span>
<span class="n">CLASSIFICATION_SCORING</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># &quot;accuracy&quot;,</span>
    <span class="c1"># &quot;balanced_accuracy&quot;,</span>
    <span class="c1"># &quot;top_k_accuracy&quot;,</span>
    <span class="c1"># &quot;average_precision&quot;,</span>
    <span class="c1"># &quot;neg_brier_score&quot;,</span>
    <span class="c1"># &quot;f1&quot;,</span>
    <span class="c1"># &quot;f1_micro&quot;,</span>
    <span class="c1"># &quot;f1_macro&quot;,</span>
    <span class="c1"># &quot;f1_weighted&quot;,</span>
    <span class="c1"># &quot;f1_samples&quot;,</span>
    <span class="c1"># &quot;neg_log_loss&quot;,</span>
    <span class="c1"># &quot;precision&quot;,</span>
    <span class="c1"># &quot;precision_micro&quot;,</span>
    <span class="c1"># &quot;precision_macro&quot;,</span>
    <span class="c1"># &quot;precision_weighted&quot;,</span>
    <span class="c1"># &quot;precision_samples&quot;,</span>
    <span class="c1"># &quot;recall&quot;,</span>
    <span class="c1"># &quot;recall_micro&quot;,</span>
    <span class="c1"># &quot;recall_macro&quot;,</span>
    <span class="c1"># &quot;recall_weighted&quot;,</span>
    <span class="c1"># &quot;recall_samples&quot;,</span>
    <span class="c1"># &quot;jaccard&quot;,</span>
    <span class="c1"># &quot;jaccard_micro&quot;,</span>
    <span class="c1"># &quot;jaccard_macro&quot;,</span>
    <span class="c1"># &quot;jaccard_weighted&quot;,</span>
    <span class="c1"># &quot;jaccard_samples&quot;,</span>
    <span class="s2">&quot;roc_auc&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># Indicate that the score is by default positive</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;worst&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="c1"># &quot;roc_auc_ovr&quot;,</span>
    <span class="c1"># &quot;roc_auc_ovo&quot;,</span>
    <span class="c1"># &quot;roc_auc_ovr_weighted&quot;,</span>
    <span class="c1"># &quot;roc_auc_ovo_weighted&quot;,</span>
<span class="p">}</span>

<span class="c1"># NOTE: All scorer objects follow the convention that higher return values are</span>
<span class="c1"># better than lower return values.</span>
<span class="n">REGRESSION_SCORING</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;explained_variance&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># Indicate that the score is by default positive</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;worst&quot;</span><span class="p">:</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;max_error&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># Indicate that the score is by default negative</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;worst&quot;</span><span class="p">:</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;neg_mean_absolute_error&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># Indicate that the score is by default negative</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;worst&quot;</span><span class="p">:</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="c1"># Indicate that the score is by default negative</span>
        <span class="s2">&quot;sign&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;worst&quot;</span><span class="p">:</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="c1"># &quot;neg_root_mean_squared_error&quot;,</span>
    <span class="c1"># &quot;neg_mean_squared_log_error&quot;,</span>
    <span class="c1"># &quot;neg_median_absolute_error&quot;,</span>
    <span class="c1"># &quot;r2&quot;,</span>
    <span class="c1"># &quot;neg_mean_poisson_deviance&quot;,</span>
    <span class="c1"># &quot;neg_mean_gamma_deviance&quot;,</span>
    <span class="c1"># &quot;neg_mean_absolute_percentage_error&quot;,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_check_estimator_class</span><span class="p">(</span>
    <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
    <span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">estimator_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ESTIMATOR_CLASSES</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The given estimator class </span><span class="si">{</span><span class="n">estimator_class</span><span class="si">}</span><span class="s2"> is not a &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;valid estimator.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_scoring_function</span><span class="p">(</span>
    <span class="n">scoring</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Callable</span><span class="p">],</span>
    <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
    <span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># if &#39;self.scoring&#39; is a string then make sure the specified</span>
    <span class="c1"># scoring function is lower-case and does not contain any whitespace</span>
    <span class="c1"># before checking whether it is actually a valid scoring function</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">scoring</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">CLASSIFICATION_SCORING</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The given scoring function </span><span class="si">{</span><span class="n">scoring</span><span class="si">}</span><span class="s2"> is not a &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;valid scorer for a classifiction task using &quot;</span>
                    <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;estimator </span><span class="si">{</span><span class="n">estimator_class</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_regressor</span><span class="p">(</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">scoring</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">REGRESSION_SCORING</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The given scoring function </span><span class="si">{</span><span class="n">scoring</span><span class="si">}</span><span class="s2"> is not a &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;valid scorer for a regression task using estimator &quot;</span>
                    <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_class</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;It could not be determined whether the given &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;&#39;ShapFire.estimator_class&#39;: </span><span class="si">{</span><span class="n">estimator_class</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;is a classifier or a regressor.&quot;</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Callable</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
        <span class="c1"># TODO: Check that &#39;self.scoring&#39; is a valid scoring function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;It is currently not possible to pass a callable scoring &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;function&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_hyperparameter_search_params</span><span class="p">(</span>
    <span class="n">hyperparameter_search</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">hyperparameter_search</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">hyperparameter_search</span> <span class="o">!=</span> <span class="n">GridSearchCV</span>
            <span class="ow">and</span> <span class="n">hyperparameter_search</span> <span class="o">!=</span> <span class="n">RandomizedSearchCV</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The given input argument &#39;hyperparameter_search&#39;: &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">hyperparameter_search</span><span class="si">}</span><span class="s2">&#39; is not a valid &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;option. Valid input values are: &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">HYPERPARAMETER_SEARCH_METHODS</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot;.&quot;</span>
            <span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_cv_params</span><span class="p">(</span><span class="n">n_splits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_repeats</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">n_splits</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The given input argument &#39;n_splits&#39; can not be less &quot;</span> <span class="o">+</span> <span class="s2">&quot;than 2.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">n_repeats</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The given input argument &#39;n_repeats&#39; can not be&quot;</span> <span class="s2">&quot;less than 1.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_reference_vector_params</span><span class="p">(</span><span class="n">reference</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">reference</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The given input argument &#39;reference&#39;: </span><span class="si">{</span><span class="n">reference</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="o">+</span> <span class="s2">&quot; is not a  valid option. Valid options are: &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">])</span>
            <span class="o">+</span> <span class="s2">&quot;.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">get_kfold_cross_validator</span><span class="p">(</span>
    <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">n_splits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_repeats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">RepeatedStratifiedKFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Based on the type of estimator that is used in the ShapFire method, this</span>
<span class="sd">    method determines how to divide a dataset into training and test folds.</span>
<span class="sd">    Calssifiers use repeated stratified k-fold cross-validation by default while</span>
<span class="sd">    regressors simply use repeated k-Fold cross-validation.</span>

<span class="sd">    Args:</span>
<span class="sd">        estimator_class: The scikit-learn or Microsoft LightGBM \</span>
<span class="sd">            tree-based estimator to use. The estimator can either be a \</span>
<span class="sd">            classifier or a regressor.</span>
<span class="sd">        n_splits: The number of folds a dataset should be divided into.</span>
<span class="sd">        n_repeats: The number of times the division of a dataset into a \</span>
<span class="sd">            certain number of folds should be repeated.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If it could not be determined whether the given \</span>
<span class="sd">            &#39;estimator_class&#39; is a classifier or a regressor.&quot;</span>

<span class="sd">    Returns:</span>
<span class="sd">        A scikit-learn cross-validator object that splits a given dataset into \</span>
<span class="sd">            training and test folds.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator_class</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_regressor</span><span class="p">(</span><span class="n">estimator_class</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">RepeatedKFold</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;It could not be determined whether the given &quot;</span>
            <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;&#39;estimator_class&#39;: </span><span class="si">{</span><span class="n">estimator_class</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;is a classifier or a regressor.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">get_roc_auc_statistics</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">:</span> <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">y_test</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For a binary classification task, compute the Area Under the Receiver</span>
<span class="sd">    Operating Characteristic Curve (ROC AUC). The ROC AUC score is calculated</span>
<span class="sd">    based on the prediction scores calculated by the given estimator.</span>

<span class="sd">    Args:</span>
<span class="sd">        estimator: A scikit-learn or Miscrosoft LightGBM estimator to use. \</span>
<span class="sd">            The estimator can either be a classifier or a regressor. The \</span>
<span class="sd">            estimator is assumed to have been trained on a training dataset \</span>
<span class="sd">            and should be evaluated on a test dataset.</span>
<span class="sd">        X_test: A test dataset.</span>
<span class="sd">        y_test: The samples associated with the target variable of the \</span>
<span class="sd">            test dataset.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the given input argument &#39;estimator&#39; is not a</span>
<span class="sd">            classifier.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Return false positive rates (fpr), true positive rates (tpr), and</span>
<span class="sd">        the ROC AUC score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Make sure the estimator given as input argument is actually a classifier</span>
    <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
        <span class="c1"># Retrieve &#39;fpr&#39;: False Positive Rate</span>
        <span class="c1">#          &#39;tpr&#39;: True Positive Rate</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span>
            <span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">estimator</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># Compute Area Under the Curve (AUC)</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">fpr</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">tpr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Internal Error. &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;The given input argument &#39;estimator&#39; needs to be a &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;classifier.&quot;</span>
        <span class="p">)</span>


<span class="k">class</span> <span class="nc">HyperparameterSearchHelper</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A ShapFire helper class for performing cross-validation and hyperparameter</span>
<span class="sd">    tuning.</span>

<span class="sd">    Args:</span>
<span class="sd">        BaseEstimator: A scikit-learn estimator class used for API \</span>
<span class="sd">            compatibility purposes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">RepeatedStratifiedKFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span><span class="p">],</span>
        <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">estimator_params</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]],</span>
        <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">hyperparameter_search</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="kc">None</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">DEFAULT_RANDOM_SEED</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A helper class to perform cross-validation and hyperparameter tuning,</span>
<span class="sd">        given (i) a valid way of generating cross-validation trin/test folds and</span>
<span class="sd">        (ii) a valid scikit-learn class for performing hyperparameter tuning.</span>

<span class="sd">        Args:</span>
<span class="sd">            cv: A scikit-learn cross-validator class for generating train/test \</span>
<span class="sd">                folds.</span>
<span class="sd">            estimator_class: The scikit-learn or Microsoft LightGBM \</span>
<span class="sd">                tree-based estimator to use. The estimator can either be a \</span>
<span class="sd">                classifier or a regressor.</span>
<span class="sd">            estimator_params: The estimator hyperparameters and corresponding \</span>
<span class="sd">                values to search or directly use. If only a single value for \</span>
<span class="sd">                each hyperparameter is provided then only cross-validation \</span>
<span class="sd">                will be performed and no hyperparameter search will be \</span>
<span class="sd">                performed. Defaults to None.</span>
<span class="sd">            scoring: The specification of a scoring function to use for \</span>
<span class="sd">                model-evaluation, i.e., a function that can be used for \</span>
<span class="sd">                assessing the prediction error of a trained model given a test \</span>
<span class="sd">                set.</span>
<span class="sd">            hyperparameter_search: The type of hyperparameter search method to \</span>
<span class="sd">                apply. Defaults to None, which simply results in the \</span>
<span class="sd">                cross-validation.</span>
<span class="sd">            n_jobs: The number of jobs to run in parallel. None means 1 while \</span>
<span class="sd">                -1 means use all processor cores. Defaults to -1.</span>
<span class="sd">            random_seed: The random seed to use for \</span>
<span class="sd">                reproducibility purposes. Defaults to \</span>
<span class="sd">                    :const:`shapfire.utils.DEFAULT_RANDOM_SEED`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Class variables corresponding to calss input arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span> <span class="o">=</span> <span class="n">estimator_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span> <span class="o">=</span> <span class="n">estimator_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="o">=</span> <span class="n">hyperparameter_search</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">random_seed</span>

        <span class="c1"># Check that the given input is valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_vars</span><span class="p">()</span>

        <span class="c1"># Publically accessible variables associated with the model that</span>
        <span class="c1"># obtained the best performance score. These variables wil eventually be</span>
        <span class="c1"># set after a call to &#39;fit()&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;HyperparameterSearchHelper&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform cross-validation and hyperparameter tuning given an input</span>
<span class="sd">        dataset. In case a single hyperparameter configuration is given as input</span>
<span class="sd">        then only cross-validation will be performed.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: An input dataset that should be utilized when performing \</span>
<span class="sd">                hyperparameter tuning coupled with cross-validation. The \</span>
<span class="sd">                dataset is assumed to contain features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>
<span class="sd">            y: The samples associated with the target variable of the dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If an invalid hyperparameter search method is specified.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An updated &#39;HyperparameterSearchHelper&#39; class object that has been \</span>
<span class="sd">            updated with the results obtained from hyperparameter tuning \</span>
<span class="sd">            coupled with cross-validation. In case a single hyperparameter \</span>
<span class="sd">            configuration is given as input then only cross-validation will be \</span>
<span class="sd">            performed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># TODO: Scoring function should be passed as argument</span>
            <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
            <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c1"># Perform no hyperparameter search just fit the estimator</span>
        <span class="c1"># with the given &#39;estimator_params&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Create model object with set random state and given input</span>
            <span class="c1"># parameters</span>
            <span class="n">args</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                <span class="o">**</span><span class="n">args</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">means</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
            <span class="n">stds</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">means</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Grid scores on development set:&quot;</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%0.3f</span><span class="s2"> (+/-</span><span class="si">%0.03f</span><span class="s2">) for </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">stds</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best score (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Otherwise perform &#39;GridSearchCV&#39; or &#39;RandomizedSearchCV&#39;</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="o">==</span> <span class="n">GridSearchCV</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="o">==</span> <span class="n">RandomizedSearchCV</span>
        <span class="p">):</span>
            <span class="c1"># Create model object with set random state</span>
            <span class="n">args</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="o">==</span> <span class="n">GridSearchCV</span><span class="p">:</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;param_grid&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span><span class="p">,</span>
                    <span class="c1"># NOTE: Do NOT refit estimator here on all the available</span>
                    <span class="c1"># data.</span>
                    <span class="s2">&quot;refit&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;return_train_score&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span> <span class="o">==</span> <span class="n">RandomizedSearchCV</span><span class="p">:</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;param_distributions&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span><span class="p">,</span>
                    <span class="c1"># NOTE: Do NOT refit estimator here on all the available</span>
                    <span class="c1"># data.</span>
                    <span class="s2">&quot;refit&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;return_train_score&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">search</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
            <span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
            <span class="n">means</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">]</span>
            <span class="n">stds</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;std_test_score&quot;</span><span class="p">]</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_params_</span>
            <span class="c1"># Report back some results...</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Grid scores on development set:&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_mean</span><span class="p">,</span> <span class="n">_std</span><span class="p">,</span> <span class="n">_params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>  <span class="c1"># noqa: FKA01</span>
                <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="p">[</span><span class="n">params</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">%0.3f</span><span class="s2"> (+/-</span><span class="si">%0.03f</span><span class="s2">) for </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">_mean</span><span class="p">,</span> <span class="n">_std</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">_params</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best score (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_check_hyperparameter_search_params</span><span class="p">(</span>
                <span class="n">hyperparameter_search</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_check_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_check_estimator_class</span><span class="p">(</span><span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">)</span>
        <span class="n">_check_scoring_function</span><span class="p">(</span>
            <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span>
        <span class="p">)</span>
        <span class="n">_check_hyperparameter_search_params</span><span class="p">(</span>
            <span class="n">hyperparameter_search</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_search</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">hyperparameter_search_helper</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">],</span>
    <span class="n">feature_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
        <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
        <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">estimator_params</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]],</span>
    <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">n_splits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_repeats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hyperparameter_search</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
        <span class="kc">None</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">DEFAULT_RANDOM_SEED</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A helper method that does hyperparameter tuning and cross-validation using a</span>
<span class="sd">    set of selected features. The method returns the best CV performace estimate</span>
<span class="sd">    along with the the hyperparameter configuration that actually achieved the</span>
<span class="sd">    best CV score using the set of selected features.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: An input dataset assumed to contain features (columns) and \</span>
<span class="sd">            corresponding observations (rows).</span>
<span class="sd">        y: The set of samples associated with the target variable \</span>
<span class="sd">            of the dataset.</span>
<span class="sd">        feature_names: A list of selected features.</span>
<span class="sd">        estimator_class: The scikit-learn or Microsoft LightGBM \</span>
<span class="sd">            tree-based estimator to use. The estimator can either be a \</span>
<span class="sd">            classifier or a regressor.</span>
<span class="sd">        estimator_params: The estimator hyperparameters and corresponding \</span>
<span class="sd">            values to search or directly use. If only a single value for \</span>
<span class="sd">            each hyperparameter is provided then only cross-validation \</span>
<span class="sd">            will be performed and no hyperparameter search will be \</span>
<span class="sd">            performed. Defaults to None.</span>
<span class="sd">        scoring: The specification of a scoring function to use for \</span>
<span class="sd">            model-evaluation, i.e., a function that can be used for \</span>
<span class="sd">            assessing the prediction error of a trained model given a test \</span>
<span class="sd">            set.</span>
<span class="sd">        n_splits: The number of folds a dataset should be divided into.</span>
<span class="sd">        n_repeats: The number of times the division of a dataset into a \</span>
<span class="sd">            certain number of folds should be repeated.</span>
<span class="sd">        hyperparameter_search: The type of hyperparameter search method to \</span>
<span class="sd">            apply. Defaults to None, which simply results in the \</span>
<span class="sd">            cross-validation.</span>
<span class="sd">        n_jobs: The number of jobs to run in parallel. None means 1 while \</span>
<span class="sd">            -1 means use all processors. Defaults to -1.</span>
<span class="sd">        random_seed: The random seed to use for \</span>
<span class="sd">            reproducibility purposes. Defaults to \</span>
<span class="sd">                :const:`shapfire.utils.DEFAULT_RANDOM_SEED`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Check &#39;X&#39; and &#39;y&#39; have the same dimensions</span>
    <span class="n">_X</span><span class="p">,</span> <span class="n">_y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">feature_names</span><span class="p">],</span> <span class="n">y</span>
    <span class="n">kfold</span> <span class="o">=</span> <span class="n">get_kfold_cross_validator</span><span class="p">(</span>
        <span class="n">estimator_class</span><span class="o">=</span><span class="n">estimator_class</span><span class="p">,</span>
        <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
        <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">hyperparameter_search_helper</span> <span class="o">=</span> <span class="n">HyperparameterSearchHelper</span><span class="p">(</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
        <span class="n">estimator_class</span><span class="o">=</span><span class="n">estimator_class</span><span class="p">,</span>
        <span class="n">estimator_params</span><span class="o">=</span><span class="n">estimator_params</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="n">hyperparameter_search</span><span class="o">=</span><span class="n">hyperparameter_search</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">hyperparameter_search_helper</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">_X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">_y</span><span class="p">)</span>

    <span class="n">best_score_</span> <span class="o">=</span> <span class="n">hyperparameter_search_helper</span><span class="o">.</span><span class="n">best_score_</span>
    <span class="n">best_params_</span> <span class="o">=</span> <span class="n">hyperparameter_search_helper</span><span class="o">.</span><span class="n">best_params_</span>
    <span class="k">return</span> <span class="n">best_score_</span><span class="p">,</span> <span class="n">best_params_</span>  <span class="c1"># type: ignore</span>


<span class="c1"># TODO: Refactor into class &#39;AutoHierarchicalAssociationClustering&#39; in file</span>
<span class="c1"># shapfire.clutering.py</span>
<span class="k">class</span> <span class="nc">FeatureSelectionHelper</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A ShapFire helper class for organizing data related to feature clusters</span>
<span class="sd">    and feature subsets.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">DEFAULT_RANDOM_SEED</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a FeatureSelectionHelper object.</span>

<span class="sd">        Args:</span>
<span class="sd">            random_seed: The random seed to use for \</span>
<span class="sd">                reproducibility purposes. Defaults to \</span>
<span class="sd">                :const:`shapfire.utils.DEFAULT_RANDOM_SEED`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Internal variables for easy access to data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nclusters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="p">[</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># TODO: No clustering has been executed</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">largest_cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">cluster_size_max</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">):</span>
                <span class="n">cluster_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">cluster_size</span> <span class="o">&gt;</span> <span class="n">cluster_size_max</span><span class="p">:</span>
                    <span class="n">cluster_size_max</span> <span class="o">=</span> <span class="n">cluster_size</span>
            <span class="k">return</span> <span class="n">cluster_size_max</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">feature_clusters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feature_clusters</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">):</span>
                <span class="n">feature_clusters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">feature_clusters</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_identify_clusters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">AutoHierarchicalAssociationClustering</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a dataset containing features (columns) and corresponding \</span>
<span class="sd">        observations (rows) identify highly associated/correlated features by \</span>
<span class="sd">        grouping these into clusters.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: An input dataset containing features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the given input argument &#39;X&#39; is not type \</span>
<span class="sd">                &#39;ndarray&#39; or &#39;DataFrame&#39;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Data pertaining to the best clustering of features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Converting input &#39;ndarray&#39; &#39;X&#39; to a &#39;DataFrame&#39;.&quot;</span><span class="p">)</span>
            <span class="n">_X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;The given input argument &#39;X&#39; is not of type &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;ndarray&#39; or &#39;DataFrame&#39;. &#39;X&#39; is instead &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># TODO: Drop a feature (dataframe column) if more than 1/3</span>
        <span class="c1">#       percent of the values in the column are missing</span>
        <span class="c1"># TODO: Replace NAN values in a column with the mean of</span>
        <span class="c1">#       of the values of the feature (dataframe column)</span>
        <span class="n">_X</span> <span class="o">=</span> <span class="n">_X</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">(</span><span class="n">cluster_labels_df</span><span class="p">,</span> <span class="n">clustering_model</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_identify_colinear_features</span><span class="p">(</span>
            <span class="n">df</span><span class="o">=</span><span class="n">_X</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cluster_labels_df</span> <span class="o">=</span> <span class="n">cluster_labels_df</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">cluster_labels_df</span><span class="p">,</span>
            <span class="n">clustering_model</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">class</span> <span class="nc">RankedDifferences</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">ascending</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        _summary_</span>

<span class="sd">        Args:</span>
<span class="sd">            reference: The data fusion method to use for producing a reference</span>
<span class="sd">                vector. Defaults to &quot;mean&quot;.</span>
<span class="sd">            ascending: The order in which values are ranked. Defaults to True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">=</span> <span class="n">reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ascending</span> <span class="o">=</span> <span class="n">ascending</span>

        <span class="c1"># Check that the given input is valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_vars</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranked_differences</span><span class="p">(</span>
            <span class="n">df</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
            <span class="n">ascending</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ascending</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">ranked_differences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">ascending</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">ties</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;average&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="c1"># Produce a reference vector using a data fusion method over the rows</span>
        <span class="c1"># of a panads dataframe</span>
        <span class="n">ref_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculcate_reference</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
        <span class="c1"># Rank the data in the reference vector (a pandas series)</span>
        <span class="n">ref_vector_ranked</span> <span class="o">=</span> <span class="n">ref_vector</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="n">ties</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="n">ascending</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>

        <span class="c1"># Rank the data in each row of the input dataframe over the columns</span>
        <span class="n">df_ranked</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">ties</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="n">ascending</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Calculate the row-wise difference between the ranked rows in the input</span>
        <span class="c1"># dataframe &#39;df&#39; and the generated (ranked) reference vector</span>
        <span class="n">diffs</span> <span class="o">=</span> <span class="n">df_ranked</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">ref_vector_ranked</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Return the mean absolute distance to the (ranked) reference vector</span>
        <span class="k">return</span> <span class="n">diffs</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">calculcate_reference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Produce a reference vector with a data fusion method over the</span>
<span class="sd">        rows.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="n">reference_vector</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">reference_vector</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">reference_vector</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">==</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span>
            <span class="n">reference_vector</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reference_vector</span>  <span class="c1"># type: ignore</span>

    <span class="k">def</span> <span class="nf">_check_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">_check_reference_vector_params</span><span class="p">(</span><span class="n">reference</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference</span><span class="p">)</span>


<div class="viewcode-block" id="ShapFire"><a class="viewcode-back" href="../../source/api/shapfire.html#shapfire.ShapFire">[docs]</a><span class="k">class</span> <span class="nc">ShapFire</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="n">_HISTORY_REQUIRED_FIELDS</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;score&quot;</span><span class="p">,</span>
        <span class="s2">&quot;feature_importances&quot;</span><span class="p">,</span>
        <span class="c1"># Data pertaining to the following fields are not needed anywhere but</span>
        <span class="c1"># returned for the sake of convenience in case a user needs the data...</span>
        <span class="s2">&quot;shap_values&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">estimator_params</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_splits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SPLITS</span><span class="p">,</span>
        <span class="n">n_repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_REPEATS</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">DEFAULT_RANDOM_SEED</span><span class="p">,</span>
        <span class="n">iterations</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The main class used for applying SHAP feature importance rank ensembling</span>
<span class="sd">        for feature selection.</span>

<span class="sd">        Args:</span>
<span class="sd">            estimator_class: The scikit-learn or Microsoft LightGBM \</span>
<span class="sd">                tree-based estimator to use. The estimator can either be a \</span>
<span class="sd">                classifier or a regressor.</span>
<span class="sd">            scoring: The specification of a scoring function to use for \</span>
<span class="sd">                model-evaluation, i.e., a function that can be used for \</span>
<span class="sd">                assessing the prediction error of a trained model given a test \</span>
<span class="sd">                set.</span>
<span class="sd">            estimator_params: The estimator hyperparameters and corresponding \</span>
<span class="sd">                values to search or directly use. If only a single value for \</span>
<span class="sd">                each hyperparameter is provided then only cross-validation \</span>
<span class="sd">                will be performed and no hyperparameter search will be \</span>
<span class="sd">                performed. Defaults to None.</span>
<span class="sd">            n_splits: The number of folds to generate in the outer loop \</span>
<span class="sd">                of a nested cross-validation. Defaults to \</span>
<span class="sd">                    :const:`shapfire.shapfire.DEFAULT_SPLITS`.</span>
<span class="sd">            n_repeats: The number of new folds that should be generated \</span>
<span class="sd">                in the outer loop of a nested cross-validation. Defaults to \</span>
<span class="sd">                    :const:`shapfire.shapfire.DEFAULT_REPEATS`.</span>
<span class="sd">            random_seed: The random seed to use for reproducibility purposes. \</span>
<span class="sd">                Defaults to :const:`shapfire.utils.DEFAULT_RANDOM_SEED`.</span>
<span class="sd">            iterations: The number of feature subsets to sample and subsequently</span>
<span class="sd">                use for model-training such that SHAP feature importance values</span>
<span class="sd">                can be extracted. Defaults to None which in turns sets the</span>
<span class="sd">                number of iterations to the size of the largest cluster of</span>
<span class="sd">                highly associated features found.</span>
<span class="sd">            reference: The data fusion method to use for producing a reference</span>
<span class="sd">                vector. Defaults to &quot;mean&quot;.</span>
<span class="sd">            n_samples: The number of random samples of rank permutations to use</span>
<span class="sd">                in a batch. Several batches of random samples are used to</span>
<span class="sd">                estimate a &quot;ranking distribution&quot; which in turn is used to</span>
<span class="sd">                determine a feature importance cut-off threshold. Defaults to</span>
<span class="sd">                1000.</span>
<span class="sd">            n_batches: The number of batches of random samples that should be</span>
<span class="sd">                used to estimate a &quot;ranking distribution&quot; which in turn is used</span>
<span class="sd">                to determine a feature importance cut-off threshold. Defaults to</span>
<span class="sd">                250.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            ranked_differences: A class attribute and pandas dataframe that</span>
<span class="sd">                specifies the final importance values associated with each</span>
<span class="sd">                of the features in the given input dataset.</span>
<span class="sd">            selected_features: A ShapFire class attribute and list that</span>
<span class="sd">                specifies the final feature subset selected by ShapFire and</span>
<span class="sd">                which is expected to achieve the best possible model</span>
<span class="sd">                performance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Class vars corresponding to input args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span> <span class="o">=</span> <span class="n">estimator_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span> <span class="o">=</span> <span class="n">estimator_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">random_seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference</span> <span class="o">=</span> <span class="n">reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">=</span> <span class="n">n_batches</span>

        <span class="c1"># Check that the given input is valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_vars</span><span class="p">()</span>

        <span class="c1"># Set random seed for reproducibility purposes</span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

        <span class="c1"># Public accessible vars associated with the most important features</span>
        <span class="c1"># These vars wil eventually be set after a call to &#39;fit()&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranked_differences</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">selected_features</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Internal vars for easy access to data associated with the importance</span>
        <span class="c1"># ranking of features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="kc">None</span><span class="p">,</span> <span class="n">FeatureSelectionHelper</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Private class variable for a progress bar that is to be updated</span>
        <span class="c1"># TODO: Determine progrss bar type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_progress_bar</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Keep a class variable around to store a plotting interface object</span>
        <span class="c1"># such that all necessary plotting methods can be accessed through it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plotting_interface</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="kc">None</span><span class="p">,</span> <span class="n">ShapFirePlottingInterface</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="ShapFire.fit"><a class="viewcode-back" href="../../source/api/shapfire.html#shapfire.ShapFire.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ShapFire&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform SHAP feature importance rank ensembling for the purpose of</span>
<span class="sd">        ranking and selecting the features that can be said to be the most</span>
<span class="sd">        important for a certain prediction task at hand.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: An input dataset that the ShapFire method should be applied to. \</span>
<span class="sd">                The dataset is assumed to contain features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>
<span class="sd">            y: The samples associated with the target variable of the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ShapFire object containing the necessary data associated with \</span>
<span class="sd">                the most important features of the given input dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Converting input &#39;ndarray&#39; &#39;X&#39; to a &#39;DataFrame&#39;.&quot;</span><span class="p">)</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="c1"># Make sure the column names are strings!</span>
            <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;The given input argument &#39;X&#39; is not of type &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;ndarray&#39; or &#39;DataFrame&#39;. &#39;X&#39; is instead &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Converting input &#39;ndarray&#39; &#39;y&#39; to a &#39;Series&#39;.&quot;</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;The given input argument &#39;X&#39; is not of type &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;ndarray&#39; or &#39;Series&#39;. &#39;X&#39; is instead &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Determine feature clustering</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span> <span class="o">=</span> <span class="n">FeatureSelectionHelper</span><span class="p">(</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="p">(</span>
            <span class="n">cluster_labels_df</span><span class="p">,</span>
            <span class="n">clustering_model</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">_identify_clusters</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">largest_cluster</span>

        <span class="c1"># Create progress bar which will be updated continuously to track the</span>
        <span class="c1"># progress of the outer cross-validation loop</span>
        <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
            <span class="n">total</span><span class="o">=</span><span class="n">total</span><span class="p">,</span>
            <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">ascii</span><span class="o">=</span><span class="s2">&quot; &gt;=&quot;</span><span class="p">,</span>
            <span class="n">bar_format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{desc:&lt;20}{percentage:3.0f}</span><span class="s2">%|</span><span class="si">{bar:25}{r_bar}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;ShapFire progress&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Perform repeated nested Cross-Validation (CV):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outer_cv_loop</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Close/stop the progress bar</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Calculate normalized SHAP feature importance scores and pick the best</span>
        <span class="c1"># feature from each of the previously found clusters</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_normalized_shap_feature_importance</span><span class="p">()</span>

        <span class="c1"># Extract and organize data associated with each tested feature subset</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reorganize_feature_importance_values</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

        <span class="n">ndf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_ranked_differences</span><span class="p">(</span><span class="n">data_dict</span><span class="o">=</span><span class="n">data_dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_discard_unimportant_feautres</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">ndf</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ShapFire.transform"><a class="viewcode-back" href="../../source/api/shapfire.html#shapfire.ShapFire.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reduce the input dataset X containing features (columns) and</span>
<span class="sd">        corresponding observations (rows), to only the columns of features</span>
<span class="sd">        selected by ShapFire.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: The original input dataset that the ShapFire method was applied \</span>
<span class="sd">                to. The dataset is assumed to contain features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the :meth:`fit` method has not yet been called.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A reduced dataset that only contains the most important features \</span>
<span class="sd">                (columns).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">selected_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">selected_features</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Method &#39;.fit(X, y)&#39; has not yet been called. &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;Simply call method &#39;.fit_transform(X, y)&#39; or call &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;.fit(X, y)&#39; before calling &#39;.transform(X)&#39;.&quot;</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="ShapFire.fit_transform"><a class="viewcode-back" href="../../source/api/shapfire.html#shapfire.ShapFire.fit_transform">[docs]</a>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform SHAP feature importance rank ensembling for the purpose of</span>
<span class="sd">        selecting the features that are the most important. Subsequently, reduce</span>
<span class="sd">        the input dataset &#39;X&#39; to only the columns of the selected features.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: An input dataset that the ShapFire method should be applied to. \</span>
<span class="sd">                The dataset is assumed to contain features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>
<span class="sd">            y: The samples associated with the target variable of the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A reduced dataset that only contains the data associated with the \</span>
<span class="sd">                most important features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="ShapFire.plot_ranking"><a class="viewcode-back" href="../../source/api/shapfire.html#shapfire.ShapFire.plot_ranking">[docs]</a>    <span class="k">def</span> <span class="nf">plot_ranking</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">groupby</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cluster&quot;</span><span class="p">,</span>
        <span class="n">rcParams</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">figsize</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">with_text</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">with_overlay</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">ax</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">Axes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Figure</span><span class="p">,</span> <span class="n">Axes</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the feature importance scores associated with each feature. The</span>
<span class="sd">        features will be ordered in the figure from best to worst and possibly</span>
<span class="sd">        according to which cluster they each belong to.</span>

<span class="sd">        Args:</span>
<span class="sd">            groupby: A string value indicating how the feature importance \</span>
<span class="sd">                ranking should be displayed in a figure. If the option \</span>
<span class="sd">                &#39;cluster&#39; is chosen, then the features are grouped and \</span>
<span class="sd">                shown in the figure based on their assigned cluster and \</span>
<span class="sd">                according to the importance rank of the best feautre in the \</span>
<span class="sd">                cluster. If &#39;feature&#39; is chosen, then the features are \</span>
<span class="sd">                shown in the figure purely according to their global rank \</span>
<span class="sd">                without any consideration to what cluster each features are a \</span>
<span class="sd">                part of.</span>
<span class="sd">            figsize: The width and height of the figure in inches. Defaults to \</span>
<span class="sd">                None.</span>
<span class="sd">            fontsize: The size of the font present in the figure. Defaults to \</span>
<span class="sd">                10.</span>
<span class="sd">            with_text: If input argument :code:`groupby` is set to \</span>
<span class="sd">                &#39;cluster&#39;, then :code:`with_text` determines whether \</span>
<span class="sd">                features that have been grouped in the figure by the cluster \</span>
<span class="sd">                they each belong to, should also be annotated with a text \</span>
<span class="sd">                label. Defaults to True.</span>
<span class="sd">            with_overlay: Depending on whether :code:`groupby` is set to \</span>
<span class="sd">                &#39;cluster&#39; or &#39;feature&#39;, groups of features or individual \</span>
<span class="sd">                features are assigned a gray-scale overlay creating a visual \</span>
<span class="sd">                grouping / delimitation of features. Defaults to True.</span>
<span class="sd">            ax: A Matplotlib Axes object. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Matplotlib Figure and Axes object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plotting_interface</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plotting_interface</span> <span class="o">=</span> <span class="n">ShapFirePlottingInterface</span><span class="p">(</span><span class="n">shapfire</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
            <span class="c1"># TODO: If fit is called again, then self._plotting_interface should</span>
            <span class="c1">#       be set to None.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plotting_interface</span><span class="o">.</span><span class="n">plot_ranking</span><span class="p">(</span>
            <span class="n">groupby</span><span class="o">=</span><span class="n">groupby</span><span class="p">,</span>
            <span class="n">rcParams</span><span class="o">=</span><span class="n">rcParams</span><span class="p">,</span>
            <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">,</span>
            <span class="n">with_text</span><span class="o">=</span><span class="n">with_text</span><span class="p">,</span>
            <span class="n">with_overlay</span><span class="o">=</span><span class="n">with_overlay</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_check_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_check_scoring_function</span><span class="p">(</span>
            <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">_check_cv_params</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The given input argument &#39;iterations&#39; can not be&quot;</span>
                    <span class="s2">&quot;less than 1.&quot;</span>
                <span class="p">)</span>

    <span class="c1"># TODO: Make public and not part of class</span>
    <span class="k">def</span> <span class="nf">_get_score</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">X_test</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">y_test</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the performance score of an estimator on a given test set.</span>

<span class="sd">        Args:</span>
<span class="sd">            estimator: A LightGBM estimator from Microsoft&#39;s LightGBM \</span>
<span class="sd">                gradient boosting decision tree framework. The estimator can \</span>
<span class="sd">                either be a classifier or a regressor. The estimator is \</span>
<span class="sd">                assumed to have been trained on a training dataset and \</span>
<span class="sd">                should be evaluated on a test dataset.</span>
<span class="sd">            X_test: A test dataset.</span>
<span class="sd">            y_test: The samples associated with the target variable of the \</span>
<span class="sd">                test dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the estimator can not be identified as being a \</span>
<span class="sd">                classifier or regressor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a dictionary with a performance score and possibly \</span>
<span class="sd">            additional data pertaining to a certain type of performance score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dict_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="c1"># Handle special scoring functions where additional data, beyond</span>
            <span class="c1"># just a score,  needs to be saved and passed on</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">==</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">:</span>
                <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">get_roc_auc_statistics</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
                    <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;fpr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fpr</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;tpr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tpr</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc</span>
                <span class="k">return</span> <span class="n">dict_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO: Not yet implemented!&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_regressor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO: Not yet implemented!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;It could not be determined whether the given &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;&#39;estimator&#39;: </span><span class="si">{</span><span class="n">estimator</span><span class="si">}</span><span class="s2"> is a classifier or a regressor.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_outer_cv_loop</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a dataset perform repeated cross-validation to estimate SHAP</span>
<span class="sd">        values and thus the importance of the different features that are</span>
<span class="sd">        contained in the input dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: The original input dataset that the ShapFire method is applied \</span>
<span class="sd">                to. The dataset is assumed to contain features (columns) and \</span>
<span class="sd">                corresponding observations (rows).</span>
<span class="sd">            y: The original set of samples associated with the target variable \</span>
<span class="sd">                of the dataset.</span>
<span class="sd">            cv: A scikit-learn cross-validator class for generating train/test \</span>
<span class="sd">                folds.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If a not yet implemented scoring function is \</span>
<span class="sd">                passed as an argument.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">repeat_number</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">get_kfold_cross_validator</span><span class="p">(</span>
            <span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span><span class="p">,</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">feature_clusters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">feature_clusters</span>  <span class="c1"># type: ignore</span>
        <span class="p">)</span>
        <span class="n">cs</span> <span class="o">=</span> <span class="n">ClusterSampler</span><span class="p">(</span><span class="n">feature_clusters</span><span class="o">=</span><span class="n">feature_clusters</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
            <span class="n">selected_features</span> <span class="o">=</span> <span class="n">cs</span><span class="o">.</span><span class="n">sample_feature_subset</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_ix</span><span class="p">,</span> <span class="n">test_ix</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)):</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_ix</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_ix</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train_ix</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">test_ix</span><span class="p">]</span>

                <span class="n">_X_train</span><span class="p">,</span> <span class="n">_y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">selected_features</span><span class="p">],</span> <span class="n">y_train</span>
                <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">(</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">_X_train</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">_y_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="p">)</span>

                <span class="c1"># Retrieve SHAP values on outer loop CV test set using</span>
                <span class="c1"># best estimator refitted on inner loop CV training + test set</span>
                <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span>
                    <span class="n">X_test</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="c1"># TODO: Make sure shap_values[1] can actually be accessed!</span>
                <span class="c1">#       else raise error!</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">selected_features</span><span class="p">,</span> <span class="n">values</span><span class="p">)),</span>
                    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_importance&quot;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">feature_importances</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
                    <span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;feature_importance&quot;</span><span class="p">],</span>
                    <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">score</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
                    <span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span>
                <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_score</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">selected_features</span><span class="p">],</span>
                    <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The scorer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="si">}</span><span class="s2">&#39; has not yet been &quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;implemented for use with ShapFire.&quot;</span>
                    <span class="p">)</span>
                <span class="n">dict_</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="c1"># &#39;score&#39; a dictionary that contains data pertaining to</span>
                    <span class="c1"># the estimate of the performance on the outer loop CV test</span>
                    <span class="c1"># set using a certain scoring measure specified by</span>
                    <span class="c1"># &#39;self.scoring&#39;.</span>
                    <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                    <span class="c1"># &#39;feature_importance&#39; is dataframe that contains feature</span>
                    <span class="c1"># names and corresponding importance values for each feature</span>
                    <span class="c1"># selected in the inner CV loop.</span>
                    <span class="s2">&quot;feature_importances&quot;</span><span class="p">:</span> <span class="n">feature_importances</span><span class="p">,</span>
                    <span class="c1"># &#39;shap_values&#39; contains the raw numpy array output from the</span>
                    <span class="c1"># SHAP Python library.</span>
                    <span class="s2">&quot;shap_values&quot;</span><span class="p">:</span> <span class="n">shap_values</span><span class="p">,</span>
                    <span class="s2">&quot;repeat_number&quot;</span><span class="p">:</span> <span class="n">repeat_number</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">repeat_number</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Update the progress bar</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="n">_history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">history</span><span class="p">)</span>
        <span class="c1"># If the current ShapFire object already has a &#39;self._history&#39;</span>
        <span class="c1"># defined then reset the dataframe so data does not accumulate</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">_history</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calculate_normalized_shap_feature_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate and organize the normalized SHAP feature importance each test</span>
<span class="sd">        fold in the cross-validation loop. Normalizing SHAP feature importance</span>
<span class="sd">        scores makes it possible to compare and aggregate results across</span>
<span class="sd">        different folds if necessary.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the internal class variable  &#39;._history&#39; is None.</span>
<span class="sd">            ValueError: If the internal class variable &#39;._feature_selector&#39; \</span>
<span class="sd">                is None.</span>
<span class="sd">            ValueError: If the internal class variable \</span>
<span class="sd">                &#39;._feature_selector._df_cluster_labels&#39; is None.</span>
<span class="sd">            ValueError: If a certain column name is not contained in the \</span>
<span class="sd">                internally used &#39;._history&#39; pandas dataframe.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A pandas dataframe that contains normalized SHAP feature importance</span>
<span class="sd">            values associated with each feature in a tested feature subset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Validate and check necessary data before proceeding</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Internal error. The internal class variable &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;._history&#39; is None. This should not happend if &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;the method is called via the &#39;.fit(X, y)&#39; method.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Internal error. The internal class variable &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;._feature_selector&#39; is None. This should not happend if &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;the method is called via the &#39;.fit(X, y)&#39; method.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">_cluster_labels_df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Internal error. The internal class variable &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;._feature_selector._df_cluster_labels &#39; is None. This &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;should not happend if the method is called via the &quot;</span>
                <span class="o">+</span> <span class="s2">&quot;&#39;.fit(X, y)&#39; method.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Verify that all required data is contained in &#39;self._history&#39;</span>
        <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_HISTORY_REQUIRED_FIELDS</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">column_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The column name </span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2"> is required but is &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;not contained in the internally used &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;&#39;._history&#39; pandas dataframe.&quot;</span>
                <span class="p">)</span>
        <span class="n">folds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">folds</span><span class="p">):</span>
            <span class="n">df_fold</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s2">&quot;feature_importances&quot;</span><span class="p">]</span>
                <span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">]</span>

            <span class="c1"># Sum feature importance value such that we can compute a</span>
            <span class="c1"># normalized feature importance value that lies in the range</span>
            <span class="c1"># [0, 1]. This makes it possible to then aggregate and compare</span>
            <span class="c1"># scores across differrent trained models.</span>
            <span class="n">total</span> <span class="o">=</span> <span class="n">df_fold</span><span class="p">[</span><span class="s2">&quot;feature_importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="c1"># Create new column with normalized feature importance scores</span>
            <span class="n">df_fold</span><span class="p">[</span><span class="s2">&quot;normalized_feature_importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">df_fold</span><span class="p">[</span><span class="s2">&quot;feature_importance&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total</span>
            <span class="p">)</span>

            <span class="c1"># Enumerate CV folds from 1...</span>
            <span class="n">df_fold</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">df_fold</span><span class="o">.</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_fold</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
                <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;test_fold&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="c1"># Set the feature name</span>
                    <span class="s2">&quot;feature_name&quot;</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">],</span>
                    <span class="c1"># Set the normalized feature importance score calculated</span>
                    <span class="c1"># based on the outer loop CV test fold</span>
                    <span class="s2">&quot;normalized_feature_importance&quot;</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span>
                        <span class="s2">&quot;normalized_feature_importance&quot;</span>
                    <span class="p">],</span>
                    <span class="c1"># Set the rank of the feature. The rank is based on the</span>
                    <span class="c1"># computed &#39;normalized_feature_importance&#39;</span>
                    <span class="s2">&quot;feature_rank&quot;</span><span class="p">:</span> <span class="n">index</span><span class="p">,</span>
                    <span class="c1"># Set the performance score that was calculated based on</span>
                    <span class="c1"># the outer loop CV test fold</span>
                    <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                    <span class="c1"># Retrieve the cluster that the feature belongs to</span>
                    <span class="s2">&quot;cluster&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="p">[</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">_cluster_labels_df</span><span class="p">[</span>
                            <span class="s2">&quot;feature_name&quot;</span>
                        <span class="p">]</span>
                        <span class="o">==</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">]</span>
                    <span class="p">][</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="p">}</span>
                <span class="n">arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">arr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_reorganize_feature_importance_values</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
        <span class="c1"># Organize data per tested feature subset</span>
        <span class="n">fsc</span> <span class="o">=</span> <span class="n">FeatureSubsetCollection</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_df</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;test_fold&quot;</span><span class="p">):</span>
            <span class="n">reduced_df</span> <span class="o">=</span> <span class="n">_df</span><span class="p">[</span>
                <span class="p">[</span>
                    <span class="s2">&quot;test_fold&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;feature_name&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;normalized_feature_importance&quot;</span><span class="p">,</span>
                <span class="p">]</span>
            <span class="p">]</span>
            <span class="n">pivot_df</span> <span class="o">=</span> <span class="n">reduced_df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span>
                <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;test_fold&quot;</span><span class="p">],</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">],</span>
                <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;normalized_feature_importance&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">pivot_df</span> <span class="o">=</span> <span class="n">pivot_df</span><span class="p">[</span><span class="s2">&quot;normalized_feature_importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span>
                <span class="n">drop</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">pivot_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pivot_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
            <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;-&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>
            <span class="n">fsc</span><span class="o">.</span><span class="n">_add_entries</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">pivot_df</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fsc</span><span class="o">.</span><span class="n">_data_dict</span>

    <span class="k">def</span> <span class="nf">_calculate_ranked_differences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="c1"># For each evaluated subset of features calculate the ranked differences</span>
        <span class="c1"># between rankings obtained from SHAP values associated with the feature</span>
        <span class="c1"># subsets and reference vectors produced based on the same data through</span>
        <span class="c1"># a data fusion method</span>
        <span class="n">evaluated_feature_subsets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="p">:</span>
            <span class="n">feature_importance_values</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">feature_importance_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ranked_differences</span> <span class="o">=</span> <span class="n">RankedDifferences</span><span class="p">(</span>
                    <span class="n">reference</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_importance_values</span><span class="p">)</span>
                <span class="n">ranked_differences</span> <span class="o">=</span> <span class="n">ranked_differences</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
                <span class="n">ranked_differences</span><span class="p">[</span>
                    <span class="s2">&quot;nsamples&quot;</span>
                <span class="p">]</span> <span class="o">=</span> <span class="n">feature_importance_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">evaluated_feature_subsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ranked_differences</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">evaluated_feature_subsets</span><span class="p">)</span>
        <span class="n">nsamples</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;nsamples&quot;</span><span class="p">]</span>
        <span class="n">ndf</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;nsamples&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Calculate weighted averages</span>
        <span class="n">ndf</span> <span class="o">=</span> <span class="n">ndf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;rows&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
        <span class="n">ndf</span> <span class="o">=</span> <span class="n">ndf</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s2">&quot;ranked_difference&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ndf</span>

    <span class="k">def</span> <span class="nf">_discard_unimportant_feautres</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Determine a feature importance cut-off threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_finder</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ThresholdFinder</span><span class="p">(</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
            <span class="n">ncols</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">nclusters</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">n_batches</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span><span class="p">,</span>
            <span class="n">n_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_finder</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="n">cluster_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">cluster_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loopkup_cluster_label</span><span class="p">(</span><span class="n">feature_name</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
            <span class="n">cluster_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cluster_label</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranked_differences</span> <span class="o">=</span> <span class="n">df</span>

        <span class="n">selected_features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
            <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ranked_difference&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_finder</span><span class="o">.</span><span class="n">lower_threshold</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">selected_features</span> <span class="o">=</span> <span class="n">selected_features</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_loopkup_cluster_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="c1"># Retrieve the cluster that the given input feature &#39;feature_name&#39;</span>
        <span class="c1"># belongs to</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_selector</span><span class="o">.</span><span class="n">_cluster_labels_df</span>  <span class="c1"># type: ignore</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">[</span>  <span class="c1"># type: ignore</span>
            <span class="n">df</span><span class="p">[</span><span class="s2">&quot;feature_name&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">feature_name</span>  <span class="c1"># type: ignore</span>
        <span class="p">][</span><span class="s2">&quot;cluster_label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>


<span class="k">class</span> <span class="nc">FeatureSubsetCollection</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_subsets</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">_add_entries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_data_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="p">],</span>
                <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">,</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>


<span class="k">class</span> <span class="nc">RefitHelper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">estimator_class</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">estimator_params</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]],</span>
        <span class="n">n_splits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_SPLITS</span><span class="p">,</span>
        <span class="n">n_repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">DEFAULT_REPEATS</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">DEFAULT_RANDOM_SEED</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            feature_names: A list of selected features.</span>
<span class="sd">            estimator_class: The scikit-learn or Microsoft LightGBM \</span>
<span class="sd">                tree-based estimator to use. The estimator can either be a \</span>
<span class="sd">                classifier or a regressor.</span>
<span class="sd">            scoring: The specification of a scoring function to use for \</span>
<span class="sd">                model-evaluation, i.e., a function that can be used for \</span>
<span class="sd">                assessing the prediction error of a trained model given a test \</span>
<span class="sd">                set.</span>
<span class="sd">            estimator_params: The estimator hyperparameters and corresponding \</span>
<span class="sd">                values to search or directly use. If only a single value for \</span>
<span class="sd">                each hyperparameter is provided then only cross-validation \</span>
<span class="sd">                will be performed and no hyperparameter search will be \</span>
<span class="sd">                performed. Defaults to None.</span>
<span class="sd">            n_splits: The number of folds to generate in the outer loop \</span>
<span class="sd">                of a nested cross-validation. Defaults to \</span>
<span class="sd">                    :const:`shapfire.shapfire.DEFAULT_SPLITS`.</span>
<span class="sd">            n_repeats: The number of new folds that should be generated \</span>
<span class="sd">                in the outer loop of a nested cross-validation. Defaults to \</span>
<span class="sd">                    :const:`shapfire.shapfire.DEFAULT_REPEATS`.</span>
<span class="sd">            random_seed: The random seed to use for reproducibility purposes. \</span>
<span class="sd">                Defaults to :const:`shapfire.utils.DEFAULT_RANDOM_SEED`.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            history: A class attribute and pandas dataframe that contains the</span>
<span class="sd">                performance score (and possibly other data) associated with each</span>
<span class="sd">                test fold in a repeated corss-validation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Class vars corresponding to input args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span> <span class="o">=</span> <span class="n">estimator_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span> <span class="o">=</span> <span class="n">estimator_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">feature_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">random_seed</span>

        <span class="c1"># Check that the given input is valid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_vars</span><span class="p">()</span>

        <span class="c1"># Set random seed for reproducibility purposes</span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

        <span class="c1"># Public accessible vars associated with the most important features</span>
        <span class="c1"># These vars wil eventually be set after a call to &#39;fit()&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;RefitHelper&quot;</span><span class="p">:</span>
        <span class="n">history</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">repeat_number</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">get_kfold_cross_validator</span><span class="p">(</span>
            <span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span><span class="p">,</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_ix</span><span class="p">,</span> <span class="n">test_ix</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)):</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_ix</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_ix</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train_ix</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">test_ix</span><span class="p">]</span>

            <span class="n">_X_train</span><span class="p">,</span> <span class="n">_y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">],</span> <span class="n">y_train</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_params</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">_X_train</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">_y_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="p">)</span>

            <span class="n">score</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_score</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">],</span>
                <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The scorer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="si">}</span><span class="s2">&#39; has not yet been &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;implemented for use with ShapFire.&quot;</span>
                <span class="p">)</span>
            <span class="n">dict_</span> <span class="o">=</span> <span class="p">{</span>
                <span class="c1"># &#39;score&#39; a dictionary that contains data pertaining to</span>
                <span class="c1"># the estimate of the performance on the outer loop CV test</span>
                <span class="c1"># set using a certain scoring measure specified by</span>
                <span class="c1"># &#39;self.scoring&#39;.</span>
                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                <span class="s2">&quot;repeat_number&quot;</span><span class="p">:</span> <span class="n">repeat_number</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">repeat_number</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">_history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">history</span><span class="p">)</span>
        <span class="c1"># If the current ShapFire object already has a &#39;self.history&#39;</span>
        <span class="c1"># defined then reset the dataframe so data does not accumulate</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">_history</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_get_score</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">,</span>
            <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">,</span>
            <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestRegressor</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">X_test</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">y_test</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the performance score of an estimator on a given test set.</span>

<span class="sd">        Args:</span>
<span class="sd">            estimator: A LightGBM estimator from Microsoft&#39;s LightGBM \</span>
<span class="sd">                gradient boosting decision tree framework. The estimator can \</span>
<span class="sd">                either be a classifier or a regressor. The estimator is \</span>
<span class="sd">                assumed to have been trained on a training dataset and \</span>
<span class="sd">                should be evaluated on a test dataset.</span>
<span class="sd">            X_test: A test dataset.</span>
<span class="sd">            y_test: The samples associated with the target variable of the \</span>
<span class="sd">                test dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the estimator can not be identified as being a \</span>
<span class="sd">                classifier or regressor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a dictionary with a performance score and possibly \</span>
<span class="sd">            additional data pertaining to a certain type of performance score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dict_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="c1"># Handle special scoring functions where additional data, beyond</span>
            <span class="c1"># just a score, needs to be saved and passed on</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">==</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">:</span>
                <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">get_roc_auc_statistics</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
                    <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;fpr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fpr</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;tpr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tpr</span>
                <span class="n">dict_</span><span class="p">[</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc</span>
                <span class="k">return</span> <span class="n">dict_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO: Not yet implemented!&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_regressor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TODO: Not yet implemented!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;It could not be determined whether the given &quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;&#39;estimator&#39;: </span><span class="si">{</span><span class="n">estimator</span><span class="si">}</span><span class="s2"> is a classifier or a regressor.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">_check_estimator_class</span><span class="p">(</span><span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">)</span>
        <span class="n">_check_scoring_function</span><span class="p">(</span>
            <span class="n">estimator_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_class</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_check_cv_params</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span><span class="p">)</span>
</code></pre></div>


  <hr>
<div class="md-source-file">
  <small>

      Last update:
      Jun 12, 2022

  </small>
</div>


            </article>
          </div>
        </div>

      </main>

        <footer class="md-footer">



  <div class="md-footer-meta md-typeset">

    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">

    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2022, NicklasXYZ.

    </div>

    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    5.0.1.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>

</div>

    </div>

  </div>
</footer>

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["toc.integrate", "navigation.sections", "search.share"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike", "staticVersions": null, "versionPath": null}}</script>


      <script src="../../_static/javascripts/bundle.37d1338f.min.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  </body>
</html>
